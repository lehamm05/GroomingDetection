{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5052cb99-e948-42d6-8444-01b23545986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02eec1df-75ab-4ac3-998a-fec45a961cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000604306a283600b730276a2039471</td>\n",
       "      <td>a9b326df4e6da61c5b6f5e1058be83a2: b8810fee2f4a...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001347c00d419eb537c0692e6e58eba</td>\n",
       "      <td>e2bd430b29412d9267886e187ba28075: say asl and ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000197b21283dc47810760e499d1f8ec</td>\n",
       "      <td>487862cd4ec27d841e2d2e80e8d91955: joint 5c7c53...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002de15312dc33d78b6e9e4b5f61f1f</td>\n",
       "      <td>a1a8f84c419e34a1a72625e2ef245516: hi a1a8f84c4...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002ee38ac5e78e7edbc4d4a556ec4b7</td>\n",
       "      <td>8150320816528784d7dfe286d781de4c: hey :) male ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160768</th>\n",
       "      <td>fffde018f39dafd4c8ef4ebaaadbec97</td>\n",
       "      <td>0a39f78bcb297ab0ebe8a29c28bfed89: bugmail: [bu...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160769</th>\n",
       "      <td>fffe4d1b08952afb8627a9b594f913c7</td>\n",
       "      <td>e5a96ed432ed5041be76d3fb1784fb95: do you want ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160770</th>\n",
       "      <td>ffff2d0e314610b1df596482d806ada9</td>\n",
       "      <td>eccc65c89e622a83cfec5827c16391de: haiiiiiiiii....</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160771</th>\n",
       "      <td>ffff74f40b58182a2521235b9db901d4</td>\n",
       "      <td>7bc167d759d9c56d43d1d46575433d35: hey 169b2106...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160772</th>\n",
       "      <td>ffffe01fc5b03a8d6b8c929d595644d9</td>\n",
       "      <td>a5b6dda9425e1d67e37432b48db51a57: anyone famil...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160773 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id  \\\n",
       "0       0000604306a283600b730276a2039471   \n",
       "1       0001347c00d419eb537c0692e6e58eba   \n",
       "2       000197b21283dc47810760e499d1f8ec   \n",
       "3       0002de15312dc33d78b6e9e4b5f61f1f   \n",
       "4       0002ee38ac5e78e7edbc4d4a556ec4b7   \n",
       "...                                  ...   \n",
       "160768  fffde018f39dafd4c8ef4ebaaadbec97   \n",
       "160769  fffe4d1b08952afb8627a9b594f913c7   \n",
       "160770  ffff2d0e314610b1df596482d806ada9   \n",
       "160771  ffff74f40b58182a2521235b9db901d4   \n",
       "160772  ffffe01fc5b03a8d6b8c929d595644d9   \n",
       "\n",
       "                                                     text sentiment  label  \n",
       "0       a9b326df4e6da61c5b6f5e1058be83a2: b8810fee2f4a...  Negative      0  \n",
       "1       e2bd430b29412d9267886e187ba28075: say asl and ...  Positive      0  \n",
       "2       487862cd4ec27d841e2d2e80e8d91955: joint 5c7c53...  Negative      0  \n",
       "3       a1a8f84c419e34a1a72625e2ef245516: hi a1a8f84c4...  Negative      0  \n",
       "4       8150320816528784d7dfe286d781de4c: hey :) male ...  Negative      0  \n",
       "...                                                   ...       ...    ...  \n",
       "160768  0a39f78bcb297ab0ebe8a29c28bfed89: bugmail: [bu...  Negative      0  \n",
       "160769  e5a96ed432ed5041be76d3fb1784fb95: do you want ...  Negative      0  \n",
       "160770  eccc65c89e622a83cfec5827c16391de: haiiiiiiiii....  Negative      0  \n",
       "160771  7bc167d759d9c56d43d1d46575433d35: hey 169b2106...  Positive      0  \n",
       "160772  a5b6dda9425e1d67e37432b48db51a57: anyone famil...  Negative      0  \n",
       "\n",
       "[160773 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv('data/dataset_eng.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66fb99a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26.2\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "print(huggingface_hub.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6106c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# login to huggingface\n",
    "from huggingface_hub import login\n",
    "login(token=\"YOUR_HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a658ecaf-d3e9-4f61-b3ab-30e146985989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 11:56:16.042861: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-01 11:56:16.161570: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model with huggingface\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\", token=\"YOUR_HUGGINGFACE_TOKEN\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Llama-3.2-1B\", num_labels=2, token=\"YOUR_HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4fafe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device Name: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print(\"CUDA Available:\", cuda_available)\n",
    "\n",
    "# print GPU name if CUDA available\n",
    "if cuda_available:\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6903de51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is loaded on device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Model is loaded on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4289b1f-0879-44b1-a749-4c2d987f218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "df = Dataset.from_pandas(dataset[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56634919-6d5f-4350-b1aa-68a6b9f67f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "# define and add the padding token if it's not already defined\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b32d64-8026-4b78-a2da-661e690fa724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 160773/160773 [01:23<00:00, 1918.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# define tokenization function\n",
    "def tokenize_function(row):\n",
    "    return tokenizer(row['text'], padding = 'max_length', truncation=True, max_length = 64)\n",
    "\n",
    "# apply tokenization to all rows\n",
    "tokenized_datasets = df.map(tokenize_function, batched=True, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb45f81e-f959-488e-8c68-d6b451338df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3bd8f65-bb52-42c9-a00b-b876be8c1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets (70/30 split)\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.3)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf314c6-a665-44e3-b971-3d609f40ac6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 112541\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1b5814-cc08-486e-91b1-b8e1d886eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef14f5a4-b159-4f37-ba7a-a642d5b44904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# load metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "# define function to compute multiple metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Get the predicted class\n",
    "\n",
    "    # Calculate each metric individually\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=1e-5,\n",
    "    logging_steps=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=8,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"no\",   \n",
    ")\n",
    "\n",
    "# define collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841da9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d93c7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1100/1100 2:13:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.025752</td>\n",
       "      <td>0.990463</td>\n",
       "      <td>0.990552</td>\n",
       "      <td>0.990463</td>\n",
       "      <td>0.990505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>0.991748</td>\n",
       "      <td>0.992397</td>\n",
       "      <td>0.991748</td>\n",
       "      <td>0.991969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.994686</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.994709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.994507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.030610</td>\n",
       "      <td>0.995667</td>\n",
       "      <td>0.995613</td>\n",
       "      <td>0.995667</td>\n",
       "      <td>0.995627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.028672</td>\n",
       "      <td>0.995439</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>0.995439</td>\n",
       "      <td>0.995377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.030624</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.995501</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.995482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.995667</td>\n",
       "      <td>0.995606</td>\n",
       "      <td>0.995667</td>\n",
       "      <td>0.995616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.033441</td>\n",
       "      <td>0.995791</td>\n",
       "      <td>0.995736</td>\n",
       "      <td>0.995791</td>\n",
       "      <td>0.995748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.033403</td>\n",
       "      <td>0.995770</td>\n",
       "      <td>0.995722</td>\n",
       "      <td>0.995770</td>\n",
       "      <td>0.995737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1100, training_loss=0.010690952529284087, metrics={'train_runtime': 8047.0253, 'train_samples_per_second': 139.854, 'train_steps_per_second': 0.137, 'total_flos': 4.205541026247475e+17, 'train_loss': 0.010690952529284087, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58540e52-d3c6-46f5-890b-3acf57791b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='377' max='377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [377/377 01:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.033403344452381134, 'eval_accuracy': 0.9957704428595123, 'eval_precision': 0.9957224211544815, 'eval_recall': 0.9957704428595123, 'eval_f1': 0.9957369656256296, 'eval_runtime': 106.9278, 'eval_samples_per_second': 451.071, 'eval_steps_per_second': 3.526, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b310a9d",
   "metadata": {},
   "source": [
    "## Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fe3d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into three datasets\n",
    "# non_grooming\n",
    "df_rest = dataset[dataset['label'] == 0]\n",
    "df_grooming = dataset[dataset['label'] == 1]\n",
    "# positive\n",
    "df_positive = df_grooming[df_grooming['sentiment'] == 'Positive']\n",
    "# negative \n",
    "df_negative = df_grooming[df_grooming['sentiment'] == 'Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af10ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into train and test\n",
    "df_rest_train, df_rest_test = train_test_split(df_rest, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d33314",
   "metadata": {},
   "source": [
    "### Positive trained and tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df5b954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "df_pos_train, df_pos_test = train_test_split(df_positive, test_size=0.3, random_state=42)\n",
    "# train data is non-grooming and positive sentiment\n",
    "pp_train_df = pd.concat([df_pos_train, df_rest_train], axis=0)\n",
    "# test data is non-grooming and positive sentiment\n",
    "pp_test_df = pd.concat([df_pos_test, df_rest_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d535e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91219</th>\n",
       "      <td>913612b7cf3923fe8ac2c2ae48ade4c2</td>\n",
       "      <td>0d3e4cee17e1ffaa7d33d252a4175ed9: that's sound...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107610</th>\n",
       "      <td>ab81aca93db9de771f86dc69ec270605</td>\n",
       "      <td>1eb17bd9642e93fa84969b71bf387a1b: night miss ya</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99407</th>\n",
       "      <td>9e1d96fcd5a9e85d74ff3735e6f2318e</td>\n",
       "      <td>03957f443c7790f9642db14bbc59df11: katie, are y...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134356</th>\n",
       "      <td>d5ee98309092b769f853217f71631d22</td>\n",
       "      <td>ac07079f18fcab57692a57e092678052: hello a0d648...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18780</th>\n",
       "      <td>1d92861841513e08e089b841f54a823b</td>\n",
       "      <td>2e265f9b8ee76269872d56d5c6c0335b: hy u home</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124274</th>\n",
       "      <td>c5f42576faf9dff95430cd77e88da27c</td>\n",
       "      <td>0bde687f1910bed528e5c889ad28ca14: hi 65bd761d6...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107498</th>\n",
       "      <td>ab4f6e28073fdfa79202d0b1e912795b</td>\n",
       "      <td>d15c7cf4f4fbea6f11f2e695c1578c94: hi 35953a67e...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136800</th>\n",
       "      <td>d9dc22a02b907953a8b3fd6237cf95f7</td>\n",
       "      <td>f0015e87cd8fbade78126b1df6bc0a02: butterflies ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152309</th>\n",
       "      <td>f289457c6452c92a0c461d94d77e5313</td>\n",
       "      <td>07e276f7a0e8953c9b961084e9f5a1ab: horny? f5f70...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126446</th>\n",
       "      <td>c974dad5ff42c5f9c03a87a821bf6fa3</td>\n",
       "      <td>b25b6b77a0087ff8385941e5545d32ea: 1f8387eb43f1...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id  \\\n",
       "91219   913612b7cf3923fe8ac2c2ae48ade4c2   \n",
       "107610  ab81aca93db9de771f86dc69ec270605   \n",
       "99407   9e1d96fcd5a9e85d74ff3735e6f2318e   \n",
       "134356  d5ee98309092b769f853217f71631d22   \n",
       "18780   1d92861841513e08e089b841f54a823b   \n",
       "...                                  ...   \n",
       "124274  c5f42576faf9dff95430cd77e88da27c   \n",
       "107498  ab4f6e28073fdfa79202d0b1e912795b   \n",
       "136800  d9dc22a02b907953a8b3fd6237cf95f7   \n",
       "152309  f289457c6452c92a0c461d94d77e5313   \n",
       "126446  c974dad5ff42c5f9c03a87a821bf6fa3   \n",
       "\n",
       "                                                     text sentiment  label  \n",
       "91219   0d3e4cee17e1ffaa7d33d252a4175ed9: that's sound...  Positive      1  \n",
       "107610    1eb17bd9642e93fa84969b71bf387a1b: night miss ya  Positive      1  \n",
       "99407   03957f443c7790f9642db14bbc59df11: katie, are y...  Positive      1  \n",
       "134356  ac07079f18fcab57692a57e092678052: hello a0d648...  Positive      1  \n",
       "18780         2e265f9b8ee76269872d56d5c6c0335b: hy u home  Positive      1  \n",
       "...                                                   ...       ...    ...  \n",
       "124274  0bde687f1910bed528e5c889ad28ca14: hi 65bd761d6...  Negative      0  \n",
       "107498  d15c7cf4f4fbea6f11f2e695c1578c94: hi 35953a67e...  Negative      0  \n",
       "136800  f0015e87cd8fbade78126b1df6bc0a02: butterflies ...  Negative      0  \n",
       "152309  07e276f7a0e8953c9b961084e9f5a1ab: horny? f5f70...  Negative      0  \n",
       "126446  b25b6b77a0087ff8385941e5545d32ea: 1f8387eb43f1...  Negative      0  \n",
       "\n",
       "[110400 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcdc923b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24855</th>\n",
       "      <td>27362c1d0e039ce767ca2f75e7ce710a</td>\n",
       "      <td>8164381b4ae95713c7266cba00fec1df: hey</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86239</th>\n",
       "      <td>8966df68adb0c7fdd807536335d6f3ab</td>\n",
       "      <td>62760245391c6d56088d814bea04baad: i'm sorry i ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107365</th>\n",
       "      <td>ab155e3047e1dcae445d584c4f6d1746</td>\n",
       "      <td>a12332f18b35f3717dd7c9ac99b00fd6: i hope you'r...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86295</th>\n",
       "      <td>897da5d708f94b6cb0a9f6664e2d6c51</td>\n",
       "      <td>a12332f18b35f3717dd7c9ac99b00fd6: who were you...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87938</th>\n",
       "      <td>8c1c09f524d3f2b6aad54ffae846b63b</td>\n",
       "      <td>5a41bf6d7766977c25b0b6a97e4e1d58: hey baby i m...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118176</th>\n",
       "      <td>bc2ece1046c5ac6149de7b97883eee46</td>\n",
       "      <td>8acede54076d243a359aef6fe111b0a3: hornyyy 4758...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38657</th>\n",
       "      <td>3d381b2fd3048f70e17dd05c352965a4</td>\n",
       "      <td>3250f1be97c8672b54290ac7cb3f1cb6: morning</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70535</th>\n",
       "      <td>705b01ca3beb2e12575d20c885783c34</td>\n",
       "      <td>b844a0a98f81c321afe1d38ae37f3c28: channel #htm...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67835</th>\n",
       "      <td>6bf3612abd388d4939edf3ca925ebeee</td>\n",
       "      <td>dcc25eefb98547160198114d030be166: hey :-) lets...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19817</th>\n",
       "      <td>1f2ad918b235d29f283a37eaf25dfe82</td>\n",
       "      <td>0a39f78bcb297ab0ebe8a29c28bfed89: bugmail: [bu...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47315 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id  \\\n",
       "24855   27362c1d0e039ce767ca2f75e7ce710a   \n",
       "86239   8966df68adb0c7fdd807536335d6f3ab   \n",
       "107365  ab155e3047e1dcae445d584c4f6d1746   \n",
       "86295   897da5d708f94b6cb0a9f6664e2d6c51   \n",
       "87938   8c1c09f524d3f2b6aad54ffae846b63b   \n",
       "...                                  ...   \n",
       "118176  bc2ece1046c5ac6149de7b97883eee46   \n",
       "38657   3d381b2fd3048f70e17dd05c352965a4   \n",
       "70535   705b01ca3beb2e12575d20c885783c34   \n",
       "67835   6bf3612abd388d4939edf3ca925ebeee   \n",
       "19817   1f2ad918b235d29f283a37eaf25dfe82   \n",
       "\n",
       "                                                     text sentiment  label  \n",
       "24855               8164381b4ae95713c7266cba00fec1df: hey  Positive      1  \n",
       "86239   62760245391c6d56088d814bea04baad: i'm sorry i ...  Positive      1  \n",
       "107365  a12332f18b35f3717dd7c9ac99b00fd6: i hope you'r...  Positive      1  \n",
       "86295   a12332f18b35f3717dd7c9ac99b00fd6: who were you...  Positive      1  \n",
       "87938   5a41bf6d7766977c25b0b6a97e4e1d58: hey baby i m...  Positive      1  \n",
       "...                                                   ...       ...    ...  \n",
       "118176  8acede54076d243a359aef6fe111b0a3: hornyyy 4758...  Negative      0  \n",
       "38657           3250f1be97c8672b54290ac7cb3f1cb6: morning  Positive      0  \n",
       "70535   b844a0a98f81c321afe1d38ae37f3c28: channel #htm...  Negative      0  \n",
       "67835   dcc25eefb98547160198114d030be166: hey :-) lets...  Positive      0  \n",
       "19817   0a39f78bcb297ab0ebe8a29c28bfed89: bugmail: [bu...  Negative      0  \n",
       "\n",
       "[47315 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08c19db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\", token=\"YOUR_HUGGINGFACE_TOKEN\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Llama-3.2-1B\", num_labels=2, token=\"YOUR_HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "347258be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is loaded on device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Model is loaded on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f785e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bafa7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd101029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 110400/110400 [00:58<00:00, 1875.13 examples/s]\n",
      "Map: 100%|██████████| 47315/47315 [00:23<00:00, 1993.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "pp_train = Dataset.from_pandas(pp_train_df[['text', 'label']])\n",
    "pp_test = Dataset.from_pandas(pp_test_df[['text', 'label']])\n",
    "pp_train_dataset = pp_train.map(tokenize_function, batched=True, batch_size = 16)\n",
    "pp_test_dataset = pp_test.map(tokenize_function, batched=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93d7d133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 110400\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aae48d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "pp_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=pp_train_dataset,\n",
    "    eval_dataset=pp_test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d786395",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0a37c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1070' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1070/1070 2:08:37, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.017854</td>\n",
       "      <td>0.993892</td>\n",
       "      <td>0.993982</td>\n",
       "      <td>0.993892</td>\n",
       "      <td>0.993934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>0.994928</td>\n",
       "      <td>0.995096</td>\n",
       "      <td>0.994928</td>\n",
       "      <td>0.994999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.996153</td>\n",
       "      <td>0.996038</td>\n",
       "      <td>0.996153</td>\n",
       "      <td>0.996026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.020551</td>\n",
       "      <td>0.996724</td>\n",
       "      <td>0.996656</td>\n",
       "      <td>0.996724</td>\n",
       "      <td>0.996676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.997027</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.997041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.026195</td>\n",
       "      <td>0.996978</td>\n",
       "      <td>0.996924</td>\n",
       "      <td>0.996978</td>\n",
       "      <td>0.996941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.027046</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.997013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.026339</td>\n",
       "      <td>0.997062</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.997062</td>\n",
       "      <td>0.996994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026563</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.997015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1070, training_loss=0.005282084218598467, metrics={'train_runtime': 7726.0925, 'train_samples_per_second': 142.892, 'train_steps_per_second': 0.138, 'total_flos': 4.092290631865467e+17, 'train_loss': 0.005282084218598467, 'epoch': 9.918887601390498})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "pp_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fb479b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='370' max='370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [370/370 01:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.026562949642539024, 'eval_accuracy': 0.9970833773644722, 'eval_precision': 0.9970188445471161, 'eval_recall': 0.9970833773644722, 'eval_f1': 0.9970146435101623, 'eval_runtime': 103.6678, 'eval_samples_per_second': 456.41, 'eval_steps_per_second': 3.569, 'epoch': 9.918887601390498}\n"
     ]
    }
   ],
   "source": [
    "pp_results = pp_trainer.evaluate()\n",
    "print(\"Evaluation results:\", pp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9766231",
   "metadata": {},
   "source": [
    "### Negative tested and trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c33a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "df_neg_train, df_neg_test = train_test_split(df_negative, test_size=0.3, random_state=42)\n",
    "# train data is non-grooming and negative sentiment\n",
    "nn_train_df = pd.concat([df_neg_train, df_rest_train], axis=0)\n",
    "# test data is non-grooming and negative sentiment\n",
    "nn_test_df = pd.concat([df_neg_test, df_rest_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d1e1d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109679</th>\n",
       "      <td>aed4fd22f4b397707c8c59aae7332515</td>\n",
       "      <td>609f7b8e566e8d514eecf112d3d3bc95: @};-</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12843</th>\n",
       "      <td>14305d38b3240a6790870d71e0215e0b</td>\n",
       "      <td>013dab612d37dc4e2cce87da5239f537: i drive a 20...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159273</th>\n",
       "      <td>fd89b32b3f049619366e552446c602b2</td>\n",
       "      <td>b679fca2e3690b4d3c60815edf4e3ca5: u still up??...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159058</th>\n",
       "      <td>fd28dc97311f6ed9ddb0db9826354891</td>\n",
       "      <td>84fb828731f4e234c54c82158127e73e: yo e03aa9707...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156641</th>\n",
       "      <td>f9647f68d20ef8425f19cece8b31a7b7</td>\n",
       "      <td>dd665a4e326e85d39591a322920f73fb: hi r u there...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124274</th>\n",
       "      <td>c5f42576faf9dff95430cd77e88da27c</td>\n",
       "      <td>0bde687f1910bed528e5c889ad28ca14: hi 65bd761d6...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107498</th>\n",
       "      <td>ab4f6e28073fdfa79202d0b1e912795b</td>\n",
       "      <td>d15c7cf4f4fbea6f11f2e695c1578c94: hi 35953a67e...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136800</th>\n",
       "      <td>d9dc22a02b907953a8b3fd6237cf95f7</td>\n",
       "      <td>f0015e87cd8fbade78126b1df6bc0a02: butterflies ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152309</th>\n",
       "      <td>f289457c6452c92a0c461d94d77e5313</td>\n",
       "      <td>07e276f7a0e8953c9b961084e9f5a1ab: horny? f5f70...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126446</th>\n",
       "      <td>c974dad5ff42c5f9c03a87a821bf6fa3</td>\n",
       "      <td>b25b6b77a0087ff8385941e5545d32ea: 1f8387eb43f1...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110654 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id  \\\n",
       "109679  aed4fd22f4b397707c8c59aae7332515   \n",
       "12843   14305d38b3240a6790870d71e0215e0b   \n",
       "159273  fd89b32b3f049619366e552446c602b2   \n",
       "159058  fd28dc97311f6ed9ddb0db9826354891   \n",
       "156641  f9647f68d20ef8425f19cece8b31a7b7   \n",
       "...                                  ...   \n",
       "124274  c5f42576faf9dff95430cd77e88da27c   \n",
       "107498  ab4f6e28073fdfa79202d0b1e912795b   \n",
       "136800  d9dc22a02b907953a8b3fd6237cf95f7   \n",
       "152309  f289457c6452c92a0c461d94d77e5313   \n",
       "126446  c974dad5ff42c5f9c03a87a821bf6fa3   \n",
       "\n",
       "                                                     text sentiment  label  \n",
       "109679             609f7b8e566e8d514eecf112d3d3bc95: @};-  Negative      1  \n",
       "12843   013dab612d37dc4e2cce87da5239f537: i drive a 20...  Negative      1  \n",
       "159273  b679fca2e3690b4d3c60815edf4e3ca5: u still up??...  Negative      1  \n",
       "159058  84fb828731f4e234c54c82158127e73e: yo e03aa9707...  Negative      1  \n",
       "156641  dd665a4e326e85d39591a322920f73fb: hi r u there...  Negative      1  \n",
       "...                                                   ...       ...    ...  \n",
       "124274  0bde687f1910bed528e5c889ad28ca14: hi 65bd761d6...  Negative      0  \n",
       "107498  d15c7cf4f4fbea6f11f2e695c1578c94: hi 35953a67e...  Negative      0  \n",
       "136800  f0015e87cd8fbade78126b1df6bc0a02: butterflies ...  Negative      0  \n",
       "152309  07e276f7a0e8953c9b961084e9f5a1ab: horny? f5f70...  Negative      0  \n",
       "126446  b25b6b77a0087ff8385941e5545d32ea: 1f8387eb43f1...  Negative      0  \n",
       "\n",
       "[110654 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f750a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93535</th>\n",
       "      <td>94d27f2475c47638194fc0c80ecdabca</td>\n",
       "      <td>2a1ac47332661b61d943d3a4e08dda5a: hey whats up...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11295</th>\n",
       "      <td>11c3faca1f15abd319ef6e7d88b164b7</td>\n",
       "      <td>a12332f18b35f3717dd7c9ac99b00fd6: i miss my ba...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73117</th>\n",
       "      <td>749864174d49b2e52b4dbd866f3ed4ed</td>\n",
       "      <td>d18fb2dc834414a71aace67bee91c432: u here?? d18...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77744</th>\n",
       "      <td>7c0004d2d9aa198bc0f920a2ed397d6b</td>\n",
       "      <td>fce23ce4bcc7bcdef65385dca0575523: you can't fo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84589</th>\n",
       "      <td>86d6b8ff254ff3031bd759487b9967c6</td>\n",
       "      <td>e50b5df92f1b6d75079d353cbc06d40f: hey i was ta...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118176</th>\n",
       "      <td>bc2ece1046c5ac6149de7b97883eee46</td>\n",
       "      <td>8acede54076d243a359aef6fe111b0a3: hornyyy 4758...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38657</th>\n",
       "      <td>3d381b2fd3048f70e17dd05c352965a4</td>\n",
       "      <td>3250f1be97c8672b54290ac7cb3f1cb6: morning</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70535</th>\n",
       "      <td>705b01ca3beb2e12575d20c885783c34</td>\n",
       "      <td>b844a0a98f81c321afe1d38ae37f3c28: channel #htm...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67835</th>\n",
       "      <td>6bf3612abd388d4939edf3ca925ebeee</td>\n",
       "      <td>dcc25eefb98547160198114d030be166: hey :-) lets...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19817</th>\n",
       "      <td>1f2ad918b235d29f283a37eaf25dfe82</td>\n",
       "      <td>0a39f78bcb297ab0ebe8a29c28bfed89: bugmail: [bu...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47424 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         conversation_id  \\\n",
       "93535   94d27f2475c47638194fc0c80ecdabca   \n",
       "11295   11c3faca1f15abd319ef6e7d88b164b7   \n",
       "73117   749864174d49b2e52b4dbd866f3ed4ed   \n",
       "77744   7c0004d2d9aa198bc0f920a2ed397d6b   \n",
       "84589   86d6b8ff254ff3031bd759487b9967c6   \n",
       "...                                  ...   \n",
       "118176  bc2ece1046c5ac6149de7b97883eee46   \n",
       "38657   3d381b2fd3048f70e17dd05c352965a4   \n",
       "70535   705b01ca3beb2e12575d20c885783c34   \n",
       "67835   6bf3612abd388d4939edf3ca925ebeee   \n",
       "19817   1f2ad918b235d29f283a37eaf25dfe82   \n",
       "\n",
       "                                                     text sentiment  label  \n",
       "93535   2a1ac47332661b61d943d3a4e08dda5a: hey whats up...  Negative      1  \n",
       "11295   a12332f18b35f3717dd7c9ac99b00fd6: i miss my ba...  Negative      1  \n",
       "73117   d18fb2dc834414a71aace67bee91c432: u here?? d18...  Negative      1  \n",
       "77744   fce23ce4bcc7bcdef65385dca0575523: you can't fo...  Negative      1  \n",
       "84589   e50b5df92f1b6d75079d353cbc06d40f: hey i was ta...  Negative      1  \n",
       "...                                                   ...       ...    ...  \n",
       "118176  8acede54076d243a359aef6fe111b0a3: hornyyy 4758...  Negative      0  \n",
       "38657           3250f1be97c8672b54290ac7cb3f1cb6: morning  Positive      0  \n",
       "70535   b844a0a98f81c321afe1d38ae37f3c28: channel #htm...  Negative      0  \n",
       "67835   dcc25eefb98547160198114d030be166: hey :-) lets...  Positive      0  \n",
       "19817   0a39f78bcb297ab0ebe8a29c28bfed89: bugmail: [bu...  Negative      0  \n",
       "\n",
       "[47424 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35ef7c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\", token=\"YOUR_HUGGINGFACE_TOKEN\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Llama-3.2-1B\", num_labels=2, token=\"YOUR_HUGGINGFACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34f32c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is loaded on device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Model is loaded on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d49e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31a4386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c5ed293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 110654/110654 [00:59<00:00, 1866.50 examples/s]\n",
      "Map: 100%|██████████| 47424/47424 [00:24<00:00, 1935.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "nn_train = Dataset.from_pandas(nn_train_df[['text', 'label']])\n",
    "nn_test = Dataset.from_pandas(nn_test_df[['text', 'label']])\n",
    "nn_train_dataset = nn_train.map(tokenize_function, batched=True, batch_size = 16)\n",
    "nn_test_dataset = nn_test.map(tokenize_function, batched=True, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ab47f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 110654\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1996e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "nn_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=nn_train_dataset,\n",
    "    eval_dataset=nn_test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4009bc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1080' max='1080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1080/1080 2:09:41, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>0.992810</td>\n",
       "      <td>0.992693</td>\n",
       "      <td>0.992810</td>\n",
       "      <td>0.992088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.995192</td>\n",
       "      <td>0.995035</td>\n",
       "      <td>0.995192</td>\n",
       "      <td>0.995004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>0.995414</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>0.995361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.995298</td>\n",
       "      <td>0.995337</td>\n",
       "      <td>0.995298</td>\n",
       "      <td>0.995316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.029805</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.995992</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>0.996017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.033194</td>\n",
       "      <td>0.996415</td>\n",
       "      <td>0.996337</td>\n",
       "      <td>0.996415</td>\n",
       "      <td>0.996356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.031902</td>\n",
       "      <td>0.996858</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.996858</td>\n",
       "      <td>0.996780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.996964</td>\n",
       "      <td>0.996903</td>\n",
       "      <td>0.996964</td>\n",
       "      <td>0.996897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.034178</td>\n",
       "      <td>0.996964</td>\n",
       "      <td>0.996904</td>\n",
       "      <td>0.996964</td>\n",
       "      <td>0.996892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1080, training_loss=0.008645707776088751, metrics={'train_runtime': 7788.3862, 'train_samples_per_second': 142.076, 'train_steps_per_second': 0.139, 'total_flos': 4.130489190941983e+17, 'train_loss': 0.008645707776088751, 'epoch': 9.988439306358382})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "nn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02f9e770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/hamm/Alvis/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='371' max='371' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [371/371 01:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.03417796641588211, 'eval_accuracy': 0.9969635627530364, 'eval_precision': 0.99690418258551, 'eval_recall': 0.9969635627530364, 'eval_f1': 0.9968921413293417, 'eval_runtime': 103.9751, 'eval_samples_per_second': 456.109, 'eval_steps_per_second': 3.568, 'epoch': 9.988439306358382}\n"
     ]
    }
   ],
   "source": [
    "nn_results = nn_trainer.evaluate()\n",
    "print(\"Evaluation results:\", nn_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
